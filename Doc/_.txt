Optimizer config: {'lr': 5e-05, 'weight_decay': 0.0, 'eps': 1e-08, 'betas': (0.9, 0.95)}
!!! SWITCHING TO 8-BIT ADAMW (BitsAndBytes) !!!
Set warmup steps = 1000
***** Running training *****
LR = 0.00005000
Min LR = 0.00001000
Weigth Decay = 0.00010000
Batch size = 8
Number of training steps = 40000
Number of training examples per epoch = 16000
Checkpoint does not exist. Starting a new training run.
Start training epoch 0, 2000 iters per inner epoch. Training dtype bf16
Epoch: [0]  [   0/2000]  eta: 2:15:01  lr: 0.000001  min_lr: 0.000001  loss: 0.1026 (0.1026)  weight_decay: 0.0001 (0.0001)  grad_norm: 4.5420 (4.5420)  time: 4.0507  data: 0.0000  max mem: 32407
Epoch: [0]  [  40/2000]  eta: 1:08:10  lr: 0.000003  min_lr: 0.000003  loss: 0.0179 (0.0427)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.2718 (1.1186)  time: 2.0902  data: 0.0000  max mem: 36224
Epoch: [0]  [  80/2000]  eta: 1:06:04  lr: 0.000005  min_lr: 0.000005  loss: 0.0221 (0.0335)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0523 (0.6088)  time: 2.0870  data: 0.0000  max mem: 36224
Epoch: [0]  [ 120/2000]  eta: 1:04:24  lr: 0.000007  min_lr: 0.000007  loss: 0.0169 (0.0290)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0448 (0.4250)  time: 1.9620  data: 0.0000  max mem: 36225
Epoch: [0]  [ 160/2000]  eta: 1:03:24  lr: 0.000009  min_lr: 0.000009  loss: 0.0126 (0.0257)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0346 (0.3303)  time: 2.0916  data: 0.0000  max mem: 36225
Epoch: [0]  [ 200/2000]  eta: 1:01:48  lr: 0.000011  min_lr: 0.000011  loss: 0.0148 (0.0239)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0355 (0.2735)  time: 2.0666  data: 0.0000  max mem: 36228
Epoch: [0]  [ 240/2000]  eta: 1:00:21  lr: 0.000013  min_lr: 0.000013  loss: 0.0159 (0.0226)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0387 (0.2364)  time: 2.1059  data: 0.0000  max mem: 36229
Epoch: [0]  [ 280/2000]  eta: 0:58:56  lr: 0.000015  min_lr: 0.000015  loss: 0.0135 (0.0219)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0402 (0.2114)  time: 1.9812  data: 0.0000  max mem: 36229
Epoch: [0]  [ 320/2000]  eta: 0:57:30  lr: 0.000017  min_lr: 0.000017  loss: 0.0153 (0.0216)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0388 (0.1906)  time: 1.9559  data: 0.0000  max mem: 36229
Epoch: [0]  [ 360/2000]  eta: 0:56:17  lr: 0.000019  min_lr: 0.000019  loss: 0.0123 (0.0211)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0368 (0.1742)  time: 2.0930  data: 0.0000  max mem: 36229
Epoch: [0]  [ 400/2000]  eta: 0:54:53  lr: 0.000021  min_lr: 0.000021  loss: 0.0144 (0.0207)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0457 (0.1618)  time: 2.0996  data: 0.0000  max mem: 36229
Epoch: [0]  [ 440/2000]  eta: 0:53:29  lr: 0.000023  min_lr: 0.000023  loss: 0.0148 (0.0204)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0414 (0.1519)  time: 2.1059  data: 0.0000  max mem: 36229
Epoch: [0]  [ 480/2000]  eta: 0:52:04  lr: 0.000025  min_lr: 0.000025  loss: 0.0150 (0.0200)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0437 (0.1433)  time: 1.9670  data: 0.0000  max mem: 36229
Epoch: [0]  [ 520/2000]  eta: 0:50:39  lr: 0.000027  min_lr: 0.000027  loss: 0.0118 (0.0198)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0409 (0.1357)  time: 1.9370  data: 0.0000  max mem: 36229
Epoch: [0]  [ 560/2000]  eta: 0:49:22  lr: 0.000028  min_lr: 0.000028  loss: 0.0148 (0.0196)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0419 (0.1293)  time: 2.0860  data: 0.0000  max mem: 36229
Epoch: [0]  [ 600/2000]  eta: 0:47:59  lr: 0.000030  min_lr: 0.000030  loss: 0.0162 (0.0195)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0491 (0.1242)  time: 2.0942  data: 0.0000  max mem: 36229
Epoch: [0]  [ 640/2000]  eta: 0:46:36  lr: 0.000032  min_lr: 0.000032  loss: 0.0162 (0.0195)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0481 (0.1196)  time: 2.1053  data: 0.0000  max mem: 36229
Epoch: [0]  [ 680/2000]  eta: 0:45:13  lr: 0.000034  min_lr: 0.000034  loss: 0.0158 (0.0192)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0547 (0.1158)  time: 2.1077  data: 0.0000  max mem: 36229
Epoch: [0]  [ 720/2000]  eta: 0:43:50  lr: 0.000036  min_lr: 0.000036  loss: 0.0126 (0.0190)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0396 (0.1121)  time: 1.9760  data: 0.0000  max mem: 36229
Epoch: [0]  [ 760/2000]  eta: 0:42:27  lr: 0.000038  min_lr: 0.000038  loss: 0.0125 (0.0189)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0423 (0.1087)  time: 1.9590  data: 0.0000  max mem: 36229
Epoch: [0]  [ 800/2000]  eta: 0:41:07  lr: 0.000040  min_lr: 0.000040  loss: 0.0152 (0.0188)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0463 (0.1058)  time: 2.0854  data: 0.0000  max mem: 36229
Epoch: [0]  [ 840/2000]  eta: 0:39:44  lr: 0.000042  min_lr: 0.000042  loss: 0.0115 (0.0186)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0482 (0.1034)  time: 2.0879  data: 0.0000  max mem: 36229
Epoch: [0]  [ 880/2000]  eta: 0:38:21  lr: 0.000044  min_lr: 0.000044  loss: 0.0129 (0.0186)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0509 (0.1012)  time: 1.9700  data: 0.0000  max mem: 36229
Epoch: [0]  [ 920/2000]  eta: 0:36:59  lr: 0.000046  min_lr: 0.000046  loss: 0.0129 (0.0185)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0428 (0.0990)  time: 1.9797  data: 0.0000  max mem: 36229
Epoch: [0]  [ 960/2000]  eta: 0:35:36  lr: 0.000048  min_lr: 0.000048  loss: 0.0164 (0.0185)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0418 (0.0972)  time: 1.9774  data: 0.0000  max mem: 36229
Epoch: [0]  [1000/2000]  eta: 0:34:16  lr: 0.000050  min_lr: 0.000050  loss: 0.0122 (0.0186)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0478 (0.0954)  time: 2.0805  data: 0.0000  max mem: 36229
Epoch: [0]  [1040/2000]  eta: 0:32:53  lr: 0.000050  min_lr: 0.000050  loss: 0.0114 (0.0184)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0439 (0.0937)  time: 2.0985  data: 0.0000  max mem: 36229
Epoch: [0]  [1080/2000]  eta: 0:31:30  lr: 0.000050  min_lr: 0.000050  loss: 0.0148 (0.0183)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0373 (0.0921)  time: 2.0864  data: 0.0000  max mem: 36229
Epoch: [0]  [1120/2000]  eta: 0:30:07  lr: 0.000050  min_lr: 0.000050  loss: 0.0152 (0.0183)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0406 (0.0905)  time: 1.9874  data: 0.0000  max mem: 36229
Epoch: [0]  [1160/2000]  eta: 0:28:45  lr: 0.000050  min_lr: 0.000050  loss: 0.0147 (0.0182)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0472 (0.0893)  time: 1.9632  data: 0.0000  max mem: 36229
Epoch: [0]  [1200/2000]  eta: 0:27:24  lr: 0.000050  min_lr: 0.000050  loss: 0.0129 (0.0182)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0420 (0.0880)  time: 2.0884  data: 0.0000  max mem: 36229
Epoch: [0]  [1240/2000]  eta: 0:26:02  lr: 0.000050  min_lr: 0.000050  loss: 0.0120 (0.0181)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0461 (0.0867)  time: 2.0959  data: 0.0000  max mem: 36229
Epoch: [0]  [1280/2000]  eta: 0:24:39  lr: 0.000050  min_lr: 0.000050  loss: 0.0122 (0.0180)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0424 (0.0854)  time: 1.9823  data: 0.0000  max mem: 36229
Epoch: [0]  [1320/2000]  eta: 0:23:17  lr: 0.000050  min_lr: 0.000050  loss: 0.0091 (0.0179)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0414 (0.0842)  time: 1.9719  data: 0.0000  max mem: 36229
Epoch: [0]  [1360/2000]  eta: 0:21:54  lr: 0.000050  min_lr: 0.000050  loss: 0.0121 (0.0178)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0440 (0.0831)  time: 1.9620  data: 0.0000  max mem: 36229
Epoch: [0]  [1400/2000]  eta: 0:20:33  lr: 0.000050  min_lr: 0.000050  loss: 0.0167 (0.0178)  weight_decay: 0.0001 (0.0001)  grad_norm: 0.0465 (0.0820)  time: 2.0664  data: 0.0000  max mem: 36229




